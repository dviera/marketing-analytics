## Look at the help page  family = ...
m.net <- glmnet(x.S, y.S, family = "binomial")
plot(m.net) # "norm"
plot(m.net, xvar = "lambda")
cf.net <- coef(m.net) # a *sparse* Matrix
image(cf.net)
install.packages(c("arules", "coin", "devtools", "gdtools", "geometry", "lavaan", "libcoin", "magick", "matrixStats", "pbapply", "pinp", "pkgbuild", "RcppArmadillo", "StanHeaders", "visNetwork", "whisker", "zip"))
install.packages(c("backports", "blogdown", "bookdown", "callr", "curl", "data.table", "Deriv", "devtools", "digest", "DT", "ellipsis", "htmlTable", "htmlwidgets", "httpuv", "knitr", "later", "mgcv", "opencpu", "pinp", "pkgconfig", "pls", "raster", "rgdal", "rgeos", "RJSONIO", "rmarkdown", "RSNNS", "sf", "sparklyr", "tensorflow", "tidyquant", "tidyr", "timetk", "tinytex", "tmap", "TTR", "xfun"))
load("https://www4.stat.ncsu.edu/~reich/BSMdata/BHNU.RData")
load(url("https://www4.stat.ncsu.edu/~reich/BSMdata/BHNU.RData"))
View(BNHU)
View(BHNU)
BHNU[["N_BBS_11"]]
BHNU_map()
BHNU_map
View(BHNU_map)
cbc.df <-
read.csv("http://goo.gl/5xQObB",
colClasses = c(seat = "factor",
price = "factor"))
View(cbc.df)
head(cbc.df[, c(-4,-5)])
xtabs(choice ~ price)
xtabs(choice ~ price, data=cbc.df)
plot(cbc.df$price)
plot(choice ~ price, data=cbc.df)
boxplot(choice ~ price)
boxplot(choice ~ price, data=cbc.df)
boxplot(price ~ choice, data=cbc.df)
library(ggplot2)
ggplot(cbc.df, aes(x=seat, y=choice)) + geom_boxplot()
ggplot(cbc.df, aes(x=seat)) + geom_boxplot()
ggplot(cbc.df, aes(x=seat, y=price)) + geom_boxplot()
ggplot(cbc.df, aes(x=seat, y=price))
ggplot(cbc.df, aes(x=seat, y=price)) + geom_dotplot()
ggplot(cbc.df, aes(x=seat, y=choice)) + geom_bar()
ggplot(cbc.df, aes(x=seat) + geom_bar()
ggplot(cbc.df, aes(x=seat)) + geom_bar()
ggplot(cbc.df, aes(x=eng)) + geom_bar()
ggplot(cbc.df, aes(x=cargo)) + geom_bar()
xtabs(cargo)
xtabs(choice ~ cargo)
xtabs(choice ~ cargo, data=cbc.df)
plot(xtabs(choice ~ cargo, data=cbc.df))
plot(choice ~ cargo, data=cbc.df)
plot(choice ~ cargo, data=cbc.df, count=TRUE)
plot(xtabs(choice ~ cargo, data=cbc.df), type="bar")
ggplot(cbc.df, aes(x=seat, y=choice)) + geom_bar()
xtabs(choice ~ cargo, data=cbc.df) %>% geom_bar()
tibble(xtabs(choice ~ cargo, data=cbc.df)) %>% geom_bar()
ggplot(cbc.df, aes(x=seat))
ggplot(cbc.df, aes(x=seat)) + geom_bar()
library(tidyverse)
count(cbc.df, seat)
count(cbc.df, seat) %>% geom_bar()
count(cbc.df, seat) %>% ggplot()
count(cbc.df, seat) %>% ggplot() %>% geom_bar()
count(cbc.df, seat) %>% ggplot() + geom_bar()
count(cbc.df, seat) %>% ggplot(aes(x=n)) + geom_bar()
count(cbc.df, seat) %>% ggplot(aes(x=sear)) + geom_bar()
count(cbc.df, seat) %>% ggplot(aes(x=seat)) + geom_bar()
count(cbc.df, seat)
plot(count(cbc.df, seat))
plot(count(cbc.df, seat), type="b")
ggplot(count(cbc.df, seat)) + geom_bar(aes(x=seat, y=n))
ggplot(count(cbc.df, seat)) + geom_bar(aes(x=seat))
ggplot(count(cbc.df, seat)) + geom_bar(aes(x=seat))
ggplot(count(cbc.df, seat)) + geom_bar(aes(x=n))
View(count(cbc.df, seat))
ggplot(count(cbc.df, seat)) + geom_bar(aes(x=seat, y=n), stat="identity")
ggplot(count(cbc.df, choice)) + geom_bar(aes(x=seat, y=n), stat="identity")
xtabs(choice ~ carpool)
xtabs(choice ~ cargo)
xtabs(choice ~ cargo, data=cbc.df)
aggregate(cbc.df, choice~cargo)
aggregate(cbc.df, choice)
install.packages(c("BatchGetSymbols", "bayesm", "classInt", "covr", "data.table", "digest", "gdtools", "htmltools", "htmlwidgets", "jomo", "JuliaCall", "keras", "KernSmooth", "maptools", "miscTools", "pkgbuild", "pkgKitten", "promises", "protolite", "purrr", "RcppArmadillo", "rgdal", "rgeos", "rlang", "shiny", "sparklyr", "strucchange", "tidyquant", "units"))
?ave()
library(caTools)
install.packages("c:/Programs/gurobi811/win64/R/gurobi_8.1-1.zip", repos = NULL)
library(gurobi)
model <- list()
model$A <- matrix(c(1,2,3,1,1,0), nrow=2, ncol=3, byrow = T)
model$obj <- c(1,1,2)
model$modelsense <- 'max'
model$rhs <- c(4,1)
model$sense <- c('<', '>')
model$vtype <- 'B'
params <- list(OutputFlag = 0)
result <- gurobi(model, params)
print('Solution: ')
print(result$objval)
print(result$x)
install.packages(c("coda","mvtnorm","devtools","loo","dagitty"))
devtools::install_github("rmcelreath/rethinking",ref="Experimental")
install.packages("Rcpp")
devtools::install_github("rmcelreath/rethinking",ref="Experimental")
library(rethinking)
?trankplot
trankplot
?rank_mat
??rank_mat
?rank_mat
?geom_histogram
trankplot
tracerplot
library(rethinking)
tracerplot()
tracerplot
?tracerplot
tracerplot
?tracerplot
library(bayesplot)
mcmc_rank_overlay()
mcmc_rank_overlay()
mcmc_rank_overlay
order(c(1,2,4,0))
rank(c(1,2,4,0))
install.packages("greta")
install.packages(c("bayesplot", "caTools", "curl", "igraph", "maptools", "Matrix", "ParamHelpers", "rgdal", "roxygen2", "testthat"))
install.packages(c("bayesplot", "BH", "blmeco", "broom", "callr", "caretEnsemble", "cli", "cubature", "data.table", "DBI", "Deriv", "dslabs", "forecast", "foreign", "fracdiff", "geepack", "geometry", "globals", "gmm", "htmlTable", "igraph", "IRkernel", "leafpop", "listenv", "mice", "miscTools", "mlogit", "mlrMBO", "msm", "multcomp", "MuMIn", "nlme", "openxlsx", "ordinal", "plot3D", "plotrix", "plyr", "quantreg", "R.utils", "RcppArmadillo", "Rdpack", "repr", "reticulate", "rgdal", "RgoogleMaps", "rmarkdown", "rsconnect", "RSQLite", "runjags", "rversions", "satellite", "simmer", "SparseM", "survival", "tidyquant", "tinytex", "tm", "TTR", "vctrs", "visNetwork"))
install.packages(c("bayesplot", "BH", "blmeco", "broom", "callr", "caretEnsemble", "cli", "cubature", "data.table", "DBI", "Deriv", "dslabs", "forecast", "foreign", "fracdiff", "geepack", "geometry", "globals", "gmm", "htmlTable", "igraph", "IRkernel", "leafpop", "listenv", "mice", "miscTools", "mlogit", "mlrMBO", "msm", "multcomp", "MuMIn", "nlme", "openxlsx", "ordinal", "plot3D", "plotrix", "plyr", "quantreg", "R.utils", "RcppArmadillo", "Rdpack", "repr", "reticulate", "rgdal", "RgoogleMaps", "rmarkdown", "rsconnect", "RSQLite", "runjags", "rversions", "satellite", "simmer", "SparseM", "survival", "tidyquant", "tinytex", "tm", "TTR", "vctrs", "visNetwork"))
install.packages(c("BH", "broom", "DBI", "foreign", "mime", "msm", "MuMIn", "nlme", "ordinal", "plot3D", "Rdpack", "repr", "reticulate", "RSQLite", "runjags", "survival", "tidyquant", "tinytex", "tm", "TTR", "vctrs", "visNetwork"))
randu(5,4)
matrix(rnorm(12), nrow=6)
mm = matrix(rnorm(12), nrow=6)
v = c(1,2)
apply(mm, 1, function(x) sqrt(sum((x-v)^2)))
mapply(sum, mm)
mapply(sum, mm, SIMPLIFY = T)
apply(mm, 2, sum)
apply(mm, 1, sum)
library(keras)
library(stringi)
?keras::loss_sparse_categorical_crossentropy()
?loss_sparse_categorical_crossentropy
install.packages("tfprobability")
install.packages("ompr")
install.packages("ompr.roi")
install.packages("rprojroot")
install.packages("rstanarm")
source('C:/Users/usuario/AppData/Local/Temp/Rar$DI00.469/forBook.R')
debug(factanal())
debug(factanal(matrix(randu(18), ncol = 3))
)
debug(factanal(matrix(rnorm(18), ncol = 3))
)
debug(factanal(matrix(rnorm(18), ncol = 3), factors = 2))
debug(factanal(matrix(rnorm(18), ncol = 3), factors = 1))
factanal(matrix(rnorm(18), ncol = 3), factors = 1)
debug(fun = factanal(matrix(rnorm(18), ncol = 3), factors = 1))
debug(fun = factanal(matrix(rnorm(18), ncol = 3), factors = 1))
?debug
debug(factanal)
factanal(matrix(rnorm(18), ncol = 3), factors = 1))
factanal(matrix(rnorm(18), ncol = 3), factors = 1)))
factanal(matrix(rnorm(18), ncol = 3), factors = 1)
factanal(matrix(rnorm(18), ncol = 3), factors = 1)
undebug(ffactanal)
undebug(factanal)
?bitrand
??bitrand
??bitran
install.packages(c("bibtex", "caret", "recipes", "RSQLite"))
install.packages(c("bibtex", "caret", "recipes", "RSQLite"))
library(DBI)
install.packages("RPostgres")
dbConnect(RPostgres::Postgres())
dbConnect(RPostgres::Postgres(PWD="admin"))
dbConnect(RPostgres::Postgres(), PWD="admin")
library(RPostgres)
Postgres()
dbConnect(Postgres())
?dbConnect
dbConnect(Postgres(), password="admin")
dbConnect(Postgres(), user="postgres", password="admin")
dbConnect(Postgres(), database = "bonds", user="postgres", password="admin")
dbConnect(Postgres(), dbname = "bonds", user="postgres", password="admin")
con <- dbConnect(Postgres(), dbname = "bonds", user="postgres", password="admin")
dbListTables(con)
library(rvest)
library(tidyverse)
get_bonds <- function(country = 18, currency = 333, type = "6%2c7%2c8%2c19"){
read_url <- function(page = 1){
url <- paste0("https://markets.businessinsider.com/bonds/finder?p=",
page,
"&borrower=&maturity=&yield=&bondtype=",
type,
"&coupon=&currency=",
currency,
"&rating=&country=",
country)
web_page <- read_html(url)
web_page
}
web_page <- read_url()
nr_results <- html_text(html_nodes(web_page, '.box-headline'))[2]
nr_results <- parse_number(nr_results)
nr_pages <- ceiling(nr_results/20)
for(page in 1:nr_pages){
cat("Accesing page", page, "out of", nr_pages, "...", "\n")
if(page == 1){
web_page <- read_url()
bonds <- html_text(html_nodes(web_page, 'td'))
bonds <- matrix(bonds, ncol = 8, byrow = TRUE)
colnam = c("ISSUER",	"CURRENCY",	"COUPON",	"YIELD",	"MOODY_RATING",	"MATURITY",
"BID",	"ASK")
bonds_df <- as.data.frame(bonds)
colnames(bonds_df) <- colnam
} else {
web_page <- read_url(page = page)
temp <- html_text(html_nodes(web_page, 'td'))
temp <- matrix(temp, ncol = 8, byrow = TRUE)
colnam = c("ISSUER",	"CURRENCY",	"COUPON",	"YIELD",	"MOODY_RATING",	"MATURITY",
"BID",	"ASK")
temp_df <- as.data.frame(temp)
colnames(temp_df) <- colnam
bonds_df <- rbind(bonds_df, temp_df)
}
}
bonds_df
}
bdf <- get_bonds()
bdf_clean <- bdf
bdf_clean$ISSUER <- gsub('\r\n\t\t\t\t\t\t\t\t\t', '', bdf_clean $ISSUER)
bdf_clean$ISSUER <- gsub('\r\n\t\t\t\t\t\t\t\t', '', bdf_clean $ISSUER)
bdf_clean$CURRENCY <- gsub('\r\n\t\t\t\t\t\t\t\t\t', '', bdf_clean $CURRENCY)
bdf_clean$CURRENCY <- gsub('\r\n\t\t\t\t\t\t\t\t', '', bdf_clean $CURRENCY)
bdf_clean$COUPON <- gsub('\r\n\t\t\t\t\t\t\t\t\t', '', bdf_clean $COUPON)
bdf_clean$COUPON <- gsub('\r\n\t\t\t\t\t\t\t\t', '', bdf_clean $COUPON)
bdf_clean$COUPON <- as.numeric(gsub('%', '', bdf_clean $COUPON))
bdf_clean$YIELD <- gsub('\r\n\t\t\t\t\t\t\t\t\t', '', bdf_clean $YIELD)
bdf_clean$YIELD <- gsub('\r\n\t\t\t\t\t\t\t\t', '', bdf_clean $YIELD)
bdf_clean$YIELD <- as.numeric(gsub('%', '', bdf_clean $YIELD))
bdf_clean$MOODY_RATING <- gsub('\r\n\t\t\t\t\t\t\t\t\t', '', bdf_clean $MOODY_RATING)
bdf_clean$MOODY_RATING <- gsub('\r\n\t\t\t\t\t\t\t\t', '', bdf_clean $MOODY_RATING)
bdf_clean$MATURITY <- gsub('\r\n\t\t\t\t\t\t\t\t\t', '', bdf_clean $MATURITY)
bdf_clean$MATURITY <- gsub('\r\n\t\t\t\t\t\t\t\t', '', bdf_clean $MATURITY)
bdf_clean$MATURITY <- parse_datetime(bdf_clean$MATURITY, "%m/%d/%Y")
bdf_clean$BID <- gsub('\r\n\t\t\t\t\t\t\t\t\t', '', bdf_clean $BID)
bdf_clean$BID <- gsub('\r\n\t\t\t\t\t\t\t\t', '', bdf_clean $BID)
bdf_clean$BID <- as.numeric(bdf_clean$BID)
bdf_clean$ASK <- gsub('\r\n\t\t\t\t\t\t\t\t\t', '', bdf_clean $ASK)
bdf_clean$ASK <- gsub('\r\n\t\t\t\t\t\t\t\t', '', bdf_clean $ASK)
bdf_clean$ASK <- as.numeric(bdf_clean$ASK)
install.packages("mlr3")
library(mlr)
detach("package:mlr", unload = TRUE)
remove.packages("mlr")
library(mlrMBO)
detach("package:mlrMBO", unload = TRUE)
remove.packages("mlrMBO")
install.packages("mlr3learners")
install.packages("mlr3pipelines")
knit_with_parameters('F:/cursos/Demand and Supply/week1.Rmd', encoding = 'UTF-8')
?coda.samples
1e6
1:1e6[-1]
1:1e6
1:1e6
1e4
1e6
500/60
1e4
1e6 - 1e4
## Load libraries
library(mclogit)
library(reshape)
library(rjags)
library(R2WinBUGS) ## for write.model
## Load the data file from mclogit
data(Transport)
summary(mclogit.mod <- mclogit(
cbind(resp,suburb)~distance+cost,
data=Transport
))
## reshape choices to a suburb-by-mode data frame with values as frequencies
transport.c <- cast(Transport,suburb~transport,value="resp")
## Get predictors in same format
cost.c <- cast(Transport,suburb~transport,value="cost")
distance.c <- cast(Transport,suburb~transport,value="distance")
model <- function() {
for (the.suburb in 1:nSuburbs) {
for (the.mode in 1:nModes ) {
log(phi[the.suburb,the.mode]) <- alpha[1] * cost[the.suburb,the.mode] + alpha[2] * distance[the.suburb,the.mode]
p[the.suburb,the.mode] <- phi[the.suburb,the.mode] / sum(phi[the.suburb,1:nModes])
}
y[the.suburb,1:nModes] ~ dmulti(p[the.suburb,1:nModes], nResp[the.suburb])
}
alpha[1] ~ dnorm(0,.01)
alpha[2] ~ dnorm(0,.01)
}
write.model(model, "model1.bug")
## Set up data
y <- as.matrix(transport.c[,2:ncol(transport.c)])
nSuburbs <- nrow(y)
nModes <- ncol(y)
nResp <- rowSums(y)
cost <- as.matrix(cost.c[,2:ncol(cost.c)])
distance <- as.matrix(distance.c[,2:ncol(cost.c)])
data <- list("y"=y,
"nResp"=nResp,
"cost"=cost,
"distance"=distance,
"nSuburbs"=nSuburbs,
"nModes"=nModes)
jags <- jags.model('model1.bug',
data = data,
n.chains = 3,
n.adapt = 100)
system.time(update(jags, 1e4))
system.time(out <- coda.samples(jags,
c('alpha', 'p'),
1e6,thin=1000))
holder <- summary(out)
gelman.diag(out)
geweke.diag(out)
## Compare the two sets of estimated coefficients
summary(mclogit.mod)
holder$statistics[1:2,]
?infert
infert$stratum
infert$case
install.packages("BEST")
library(JuliaCall)
detach("package:JuliaCall", unload = TRUE)
remove.packages("JuliaCall")
install.packages("JuliaCall")
library(JuliaCall)
julia_setup()
julia_setup(JULIA_HOME = "C:/Programs/Julia-1.3.0/")
julia_setup(JULIA_HOME = "C:/Programs/Julia-1.3.0/bin/")
julia_setup(JULIA_HOME = "C:/Programs/Julia-1.3.0/bin/")
julia_setup(JULIA_HOME = "C:/Programs/Julia-1.3.0/bin")
julia_setup()
library(JuliaCall)
julia_setup()
julia_setup(JULIA_HOME = "C:/Programs/Julia-1.3.0/bin")
julia_setup(JULIA_HOME = "C:/Programs/Julia-1.3.0/bin")
julia_setup(JULIA_HOME = "C:/Programs/Julia-1.3.0/bin")
detach("package:JuliaCall", unload = TRUE)
remove.packages("JuliaCall")
install.packages("JuliaCall")
library(JuliaCall)
julia_setup(JULIA_HOME = "C:/Programs/Julia-1.3.0/bin")
julia_setup(JULIA_HOME = "C:/Programs/Julia-1.3.0/bin")
# example
Baa3 <- bdf_clean %>% filter(MOODY_RATING == "Baa3", CURRENCY == "USD")
source('C:/Users/usuario/Desktop/dev/valuation/curso/bonds_corporate.R', echo=TRUE)
pwd
write.csv(bdf_clean, "c:/Users/usuario/Desktop/bdf_clean.csv")
install.packages("ggplot2")
library(ggplot2)
elder_cohort <-
c(10567,9763,8327,8318,7108,6280,6279,5873,4986,3296,2986,1357)
younger_cohort <-
c(25000,24500,24324,19500,15078,11879,10856,10543,10234,9678,8542,
6321 )
total <- elder_cohort+younger_cohort
women_cohort <- total - total*0.46
men_cohort <- total - women_cohort
cohort_dataset <-
data.frame(rbind(elder_cohort,younger_cohort,women_cohort,
men_cohort))
colnames(cohort_dataset) <- c(seq(1:12))
View(cohort_dataset)
retention_younger <- younger_cohort/sum(younger_cohort)
retention_elder <- elder_cohort/sum(elder_cohort)
retention_women <- women_cohort/sum(women_cohort)
retention_men <- men_cohort/sum(men_cohort)
retention_rates <- rbind(retention_younger,retention_
elder,retention_women,
retention_men)
colnames(retention_rates) <- c(seq(1:12))
retention_rates <- rbind(retention_younger,retention_elder,retention_women,
retention_men)
colnames(retention_rates) <- c(seq(1:12))
retention_plot <- ggplot() + geom_line(aes(x =
seq(1:12),retention_younger, colour = "younger")) +
geom_line(aes(x = seq(1:12),retention_elder,colour =
"elder")) + geom_line(aes(x = seq(1:12),retention_women,
colour = "women")) + geom_line(aes(x = seq(1:12),
retention_men, colour = "men"))
retention_plot
appname <- "tupoto"
q <- paste0("
SELECT
user_id,
TO_CHAR(CONVERT_TIMEZONE('UTC', 'Europe/Amsterdam', derived_tstamp),'YYYY ww') AS yw
FROM atomic.events
WHERE app_id = '", appname, "' AND derived_tstamp >= '2018-01-01'
GROUP BY 1,2;
")
conn <- dbConnect(driver, url) # make the database connection - this is from the RJDBC package (library(RJDBC))
dbdata <- dbGetQuery(conn, q)  # get the data
dbDisconnect(conn)             # close the connection
q
drv <- dbDriver("PostgreSQL")
library(RPostgres)
?dbDriver
drv <- dbDriver("PostgreSQL")
?Postgres
library(RPostgres)
con <- DBI::dbConnect(RPostgres::Postgres())
library(DBI)
con <- DBI::dbConnect(Postgres())
con <- DBI::dbConnect(Postgres(),'admin')
?dbConnect
con <- DBI::dbConnect(Postgres(), user="postgres", password="admin", host="localhost")
install.packages("d3Network")
install.packages("xlsx")
library(RCurl)
URL <- "https://raw.githubusercontent.com/christophergandrud/d3Network/sankey/JSONdata/energy.json"
Energy <- getURL(URL, ssl.verifypeer = FALSE)
# Convert to data frame
EngLinks <- JSONtoDF(jsonStr = Energy, array = "links")
EngNodes <- JSONtoDF(jsonStr = Energy, array = "nodes")
# Plot
d3Sankey(Links = EngLinks, Nodes = EngNodes, Source = "source",
Target = "target", Value = "value", NodeID = "name",
fontsize = 12, nodeWidth = 30, width = 700)
library(d3Network)
library(RCurl)
URL <- "https://raw.githubusercontent.com/christophergandrud/d3Network/sankey/JSONdata/energy.json"
Energy <- getURL(URL, ssl.verifypeer = FALSE)
# Convert to data frame
EngLinks <- JSONtoDF(jsonStr = Energy, array = "links")
EngNodes <- JSONtoDF(jsonStr = Energy, array = "nodes")
# Plot
d3Sankey(Links = EngLinks, Nodes = EngNodes, Source = "source",
Target = "target", Value = "value", NodeID = "name",
fontsize = 12, nodeWidth = 30, width = 700)
library(RCurl)
URL <- "https://raw.githubusercontent.com/christophergandrud/d3Network/sankey/JSONdata/energy.json"
Energy <- getURL(URL, ssl.verifypeer = FALSE)
# Convert to data frame
EngLinks <- JSONtoDF(jsonStr = Energy, array = "links")
EngNodes <- JSONtoDF(jsonStr = Energy, array = "nodes")
d3Sankey(Links = EngLinks, Nodes = EngNodes, Source = "source",
Target = "target", Value = "value", NodeID = "name",
fontsize = 12, nodeWidth = 30, width = 700)
x <- d3Sankey(Links = EngLinks, Nodes = EngNodes, Source = "source",
Target = "target", Value = "value", NodeID = "name",
fontsize = 12, nodeWidth = 30, width = 700)
plot(x)
x
x <- d3Sankey(Links = EngLinks, Nodes = EngNodes, Source = "source",
Target = "target", Value = "value", NodeID = "name",
fontsize = 12, nodeWidth = 30, width = 700)
install.packages("tensorflow")
library(tensorflow)
install_tensorflow()
install_tensorflow(version = "nightly")
use_condaenv("ML")
use_condaenv("~/ML")
use_condaenv("C:\Programs\Miniconda3\envs\ML")
use_condaenv("C:/Programs/Miniconda3/envs/ML")
install_tensorflow()
use_condaenv("C:/Programs/Miniconda3/envs/r-reticulate/")
install_tensorflow()
install_tensorflow()
use_condaenv(condaenv = "C:/Programs/Miniconda3/envs/r-reticulate/", required = TRUE)
install_tensorflow()
use_condaenv(condaenv = "C:/Programs/Miniconda3/envs/r-reticulate/", required = TRUE)
install_tensorflow()
install_tensorflow()
use_condaenv(condaenv = "C:/Programs/Miniconda3/envs/r-reticulate/", required = TRUE)
install_tensorflow()
install_tensorflow()
install_tensorflow()
install_tensorflow()
install_tensorflow()
install_tensorflow()
install_tensorflow()
install_tensorflow()
install_tensorflow()
library(keras)
fashion_mnist <- dataset_fashion_mnist()
c(train_images, train_labels) %<-% fashion_mnist$train
c(test_images, test_labels) %<-% fashion_mnist$test
detach("package:keras", unload = TRUE)
remove.packages("keras")
install.packages("keras")
library(keras)
detach("package:keras", unload = TRUE)
library(keras)
detach("package:keras", unload = TRUE)
reticulate::use_condaenv("C:/Programs/Miniconda3/envs/r-reticulate/")
library(keras)
library(tfdatasets)
?reuters
keras::dataset_reuters()
?text
setwd("C:/Users/usuario/Desktop/dev/github/github/marketing-analytics")
setwd("C:/Users/usuario/Desktop/dev/github/github/marketing-analytics/churn/")
data <- read.csv("data/Churn.xls", header = TRUE)
library(readxl)
churn <- read_excel("data/Churn.xls")
View(Churn)
View(churn)
devtools::install_github('catboost/catboost', subdir = 'catboost/R-package')
devtools::install_github('catboost/catboost', subdir = 'catboost/R-package')
devtools::install_github('catboost/catboost', subdir = 'catboost/R-package')
devtools::install_github('catboost/catboost', subdir = 'catboost/R-package')
devtools::install_url('https://github.com/catboost/catboost/releases/download/v0.21/catboost-R-Windows-0.21.tgz', INSTALL_opts = c("--no-multiarch"))
devtools::install_url('https://github.com/catboost/catboost/releases/download/v0.21/catboost-R-Windows-0.21.tgz', INSTALL_opts = c("--no-multiarch"))
devtools::install_url('https://github.com/catboost/catboost/releases/download/v0.21/catboost-R-Windows-0.21.tgz', INSTALL_opts = c("--no-multiarch"))
library(jsonlite)
detach("package:jsonlite", unload = TRUE)
library(jsonlite)
remove.packages("jsonlite")
install.packages("jsonlite")
